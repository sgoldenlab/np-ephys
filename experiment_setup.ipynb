{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986df8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873715e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from tools.settings import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5d8286",
   "metadata": {},
   "source": [
    "## Example from mtscomp for compression and decompression\n",
    "```python\n",
    "import numpy as np\n",
    "from mtscomp.mtscomp import compress, decompress\n",
    "\n",
    "# Compress a .bin file into a pair .cbin (compressed binary file) and .ch (JSON file).\n",
    "compress('data.bin', 'data.cbin', 'data.ch', sample_rate=20000., n_channels=256, dtype=np.int16)\n",
    "# Decompress a pair (.cbin, .ch) and return an object that can be sliced like a NumPy array.\n",
    "arr = decompress('data.cbin', 'data.ch')\n",
    "X = arr[start:end, :]  # decompress the data on the fly directly from the file on disk\n",
    "arr.close()  # Close the file when done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28dd1a9",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc451a",
   "metadata": {},
   "source": [
    "#### set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e817534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for recordings in:\n",
      "\t/mnt/fasthd/4_Behavioral_Sensitization/to_compress\n"
     ]
    }
   ],
   "source": [
    "paths = settings.paths\n",
    "experiment = settings.experiment\n",
    "\n",
    "raw_drive = paths.drive\n",
    "expt_folder = experiment.dir\n",
    "batch_folder = raw_drive / expt_folder / 'to_compress'\n",
    "print(f'Looking for recordings in:\\n\\t{batch_folder}')\n",
    "\n",
    "# Define the base path where the project folders for each subject will be located\n",
    "    # this should or will contain subject folders like 'NP02_R1', etc.\n",
    "# For our projects, for each experiment `data_dir` by default is \"1_Recordings\"\n",
    "project_base_path = raw_drive / expt_folder / paths.data_dir\n",
    "raw_dir = paths.raw_dir  # folder name in session folder where compressed recordings will go\n",
    "\n",
    "# target_folder = batch_folder.parent / 'compressed_recordings'\n",
    "# target_folder.mkdir(exist_ok=True)\n",
    "# print(f'\\nCompressed recordings will be saved to:\\n\\t{target_folder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5cb8cb",
   "metadata": {},
   "source": [
    "set subject / recording pairs to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb58acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the following recordings:\n",
      "{   'BS03_R3': {'concatenate': False, 'multiple_shanks': [True, False]},\n",
      "    'BS05_R2': {'concatenate': False, 'multiple_shanks': [True, False]}}\n"
     ]
    }
   ],
   "source": [
    "recording_pairs = experiment.recordings\n",
    "print(\"Processing the following recordings:\")\n",
    "pprint(recording_pairs, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68265ec",
   "metadata": {},
   "source": [
    "### before compressions...\n",
    "If you haven't yet, set up experiment folder structure for each recording using the `set_up_folders` tool.  \n",
    "\n",
    "Currently there are two options:   \n",
    "* *Command-line tool*\n",
    "    * Useful to set up structure for one session, or to have some more control over output.\n",
    "    * If you installed with uv, should be able to use the following to see basic usage, see README for further instructions.  \n",
    "    \n",
    "        ```bash\n",
    "        uv run set_up_folders --help\n",
    "        ```\n",
    "* *Set up default structures (histology & recording templates)*\n",
    "    * For all recordings in `recording_pairs`, or single recording if `recording_name` is other than `None`.\n",
    "    * See further instructions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f984a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.set_up_folders import setup_folders_from_dict\n",
    "\n",
    "# set to True to see what folders would be created without actually creating them\n",
    "in_debug_mode = False\n",
    "\n",
    "recording_name = None\n",
    "\n",
    "if recording_name is not None:\n",
    "    print(f'---setting up folders for recording {recording_name}...')\n",
    "else:\n",
    "    print(f'---setting up folders for all recordings in recording_pairs...')\n",
    "setup_folders_from_dict(\n",
    "    recording_pairs,\n",
    "    base_path=project_base_path,\n",
    "    debug=in_debug_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bdbce",
   "metadata": {},
   "source": [
    "## compress recordings\n",
    "\n",
    "**single recording**  \n",
    "To compress a single recording, assign `recording_name` to one of the entries in `run_config.toml` under `[experiment.recordings]` header, for example \"NP02_R1\".  \n",
    "Run the `compress_recordings` cell afterwards to compress the recording to `target_folder`.  \n",
    "\n",
    "**batch compress**  \n",
    "To batch compress, simply leave `recording_name` as `None`, then run the `compress_recordings` cell to compresse all recordings in `recording_pairs` to `target_folder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd25127",
   "metadata": {},
   "source": [
    "set parallel processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28185f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parallel Job parameters:\n",
      "{'chunk_duration': 5, 'n_threads': 10}\n"
     ]
    }
   ],
   "source": [
    "num_cores = os.cpu_count()\n",
    "job_kwargs=dict(\n",
    "    n_threads=round(num_cores*0.8),\n",
    "    chunk_duration=5,\n",
    ")\n",
    "print(\"\\nParallel Job parameters:\")\n",
    "pprint(job_kwargs, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb51f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to other than None to compress specific raw recording (including multiple segments)\n",
    "# e.g. \"NP02_R1\", or keep as None to batch compress all recordings in recording_pairs\n",
    "recording_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.compression import compress_recordings\n",
    "# TODO: fix pathing on multiprobe, multishank recs, + place in subfolder in compression dir\n",
    "if recording_name is not None:\n",
    "    # compress single recording session\n",
    "    properties = recording_pairs[recording_name]\n",
    "    print(f'---processing single recording')\n",
    "    compress_recordings(\n",
    "        {recording_name: properties},\n",
    "        batch_folder,\n",
    "        raw_dir,\n",
    "        project_base_path=project_base_path,\n",
    "        job_kwargs=job_kwargs\n",
    "    )\n",
    "else:\n",
    "    # compress all recording sessions\n",
    "    print(f'---processing all recordings in recording_pairs...')\n",
    "    compress_recordings(\n",
    "        recording_pairs,\n",
    "        batch_folder,\n",
    "        raw_dir,\n",
    "        project_base_path=project_base_path,\n",
    "        job_kwargs=job_kwargs\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np-ephys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
